{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='x-large')\n",
    "plt.rc('ytick', labelsize='x-large')\n",
    "plt.rc('axes', labelsize='x-large')\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['treatment', 'labs', 'baseline', 'outcomes', 'trt_outcomes'])\n",
      "dict_keys(['pids', 'data', 'obs', 'names'])\n",
      "dict_keys(['treatment', 'labs', 'baseline', 'outcomes', 'trt_outcomes'])\n",
      "dict_keys(['pids', 'data', 'obs', 'names'])\n"
     ]
    }
   ],
   "source": [
    "with open('1_mmrf_dataset_type.pkl','rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "with open('1_mmrf_dataset_2mos_type.pkl','rb') as f:\n",
    "    dataset_2mos = pickle.load(f)\n",
    "print (dataset.keys())\n",
    "print(dataset['baseline'].keys())\n",
    "print (dataset_2mos.keys())\n",
    "print(dataset_2mos['baseline'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_tensors import clean_baseline, clean_labs, get_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Restrict all data to share a global ordering over patient ids (from outcomes)\n",
    "* Plot distribution over outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dset = {}\n",
    "outcomes_type = 'mortality' # or 'mortality'\n",
    "\n",
    "if outcomes_type == 'mortality': \n",
    "    new_dset['patient_ids'] = dataset['outcomes']['pids']\n",
    "    new_dset['y_data']   = dataset['outcomes']['data']\n",
    "    new_dset['event_obs']= dataset['outcomes']['obs']\n",
    "elif outcomes_type == 'trt_resp':\n",
    "    new_dset['patient_ids'] = dataset['trt_outcomes']['pids']\n",
    "    new_dset['y_data']      = dataset['trt_outcomes']['data']\n",
    "    new_dset['event_obs']   = dataset['trt_outcomes']['obs']\n",
    "    new_dset['tr_names']    = dataset['trt_outcomes']['names']\n",
    "    \n",
    "pts = new_dset['patient_ids'].tolist()\n",
    "for k in ['treatment','labs','baseline']:\n",
    "    pts_src = dataset[k]['pids'].tolist()\n",
    "    idx_map = np.array([pts_src.index(v) for v in pts])\n",
    "    new_dset[k+'_data'] = dataset[k]['data'][idx_map]\n",
    "    new_dset[k+'_m']    = dataset[k]['obs'][idx_map]\n",
    "    new_dset[k+'_names']= dataset[k]['names']\n",
    "    \n",
    "new_dset_2mos = {}\n",
    "\n",
    "if outcomes_type == 'mortality':     \n",
    "    new_dset_2mos['patient_ids'] = dataset_2mos['outcomes']['pids']\n",
    "    new_dset_2mos['y_data']      = dataset_2mos['outcomes']['data']\n",
    "    new_dset_2mos['event_obs']   = dataset_2mos['outcomes']['obs']\n",
    "elif outcomes_type == 'trt_resp': \n",
    "    new_dset_2mos['patient_ids'] = dataset_2mos['trt_outcomes']['pids']\n",
    "    new_dset_2mos['y_data']      = dataset_2mos['trt_outcomes']['data']\n",
    "    new_dset_2mos['event_obs']   = dataset_2mos['trt_outcomes']['obs']\n",
    "    new_dset_2mos['tr_names']    = dataset_2mos['trt_outcomes']['names']\n",
    "    new_dset_2mos['ym_data']     = dataset_2mos['outcomes']['data']\n",
    "    new_dset_2mos['ce']     = dataset_2mos['outcomes']['obs']\n",
    "\n",
    "pts = new_dset_2mos['patient_ids'].tolist()\n",
    "for k in ['treatment','labs','baseline']:\n",
    "    pts_src = dataset_2mos[k]['pids'].tolist()\n",
    "    idx_map = np.array([pts_src.index(v) for v in pts])\n",
    "    new_dset_2mos[k+'_data'] = dataset_2mos[k]['data'][idx_map]\n",
    "    new_dset_2mos[k+'_m']    = dataset_2mos[k]['obs'][idx_map]\n",
    "    new_dset_2mos[k+'_names']= dataset_2mos[k]['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of treatment data: (1001, 33, 6)\n",
      "shape of lab data: (1001, 33, 16)\n",
      "shape of baseline data: (1001, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of treatment data: {new_dset_2mos[\"treatment_data\"].shape}')\n",
    "print(f'shape of lab data: {new_dset_2mos[\"labs_data\"].shape}')\n",
    "print(f'shape of baseline data: {new_dset_2mos[\"baseline_data\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Visualize outcome values after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.53333333333333 70.63333333333334 65.23333333333333 64.66666666666667\n",
      " 65.83333333333333 65.23333333333333 58.2 58.03333333333333\n",
      " 57.56666666666667 57.56666666666667 52.1 17.4 43.666666666666664\n",
      " 21.233333333333334 41.56666666666667 41.43333333333333 39.53333333333333\n",
      " 12.666666666666666 34.36666666666667 30.866666666666667\n",
      " 16.266666666666666 30.333333333333332 29.0 28.066666666666666\n",
      " 71.16666666666667 71.43333333333334 67.26666666666667 66.76666666666667\n",
      " 65.56666666666666 60.13333333333333 57.86666666666667 61.833333333333336\n",
      " 22.633333333333333 58.166666666666664 57.1 54.96666666666667\n",
      " 52.06666666666667 53.46666666666667 52.333333333333336 54.2\n",
      " 51.93333333333333 52.733333333333334 53.56666666666667 51.13333333333333\n",
      " 52.53333333333333 50.06666666666667 51.8 47.2 48.13333333333333 48.9 47.6\n",
      " 42.7 47.13333333333333 49.13333333333333 46.46666666666667 43.3\n",
      " 43.46666666666667 45.7 44.7 37.36666666666667 45.2 43.0 41.93333333333333\n",
      " 41.7 36.2 39.56666666666667 39.8 41.56666666666667 41.666666666666664\n",
      " 37.96666666666667 40.6 38.9 39.56666666666667 38.43333333333333\n",
      " 38.96666666666667 39.3 40.13333333333333 39.13333333333333\n",
      " 36.666666666666664 28.966666666666665 2.933333333333333 32.9\n",
      " 34.266666666666666 24.066666666666666 34.7 32.46666666666667\n",
      " 32.56666666666667 32.1 32.7 29.966666666666665 29.4 29.733333333333334\n",
      " 28.466666666666665 29.133333333333333 27.233333333333334\n",
      " 26.633333333333333 41.266666666666666 59.53333333333333\n",
      " 48.333333333333336 32.666666666666664 13.866666666666667 39.7 34.6\n",
      " 35.36666666666667 65.63333333333334 55.36666666666667 37.46666666666667\n",
      " 66.0 59.8 50.9 44.86666666666667 45.2 4.0 37.233333333333334\n",
      " 10.633333333333333 26.033333333333335 62.86666666666667 67.0\n",
      " 65.53333333333333 66.53333333333333 63.46666666666667 60.0\n",
      " 42.733333333333334 60.56666666666667 60.13333333333333 58.2 59.1 57.3\n",
      " 41.733333333333334 58.233333333333334 59.766666666666666 17.3 54.4\n",
      " 56.333333333333336 56.43333333333333 57.46666666666667 55.36666666666667\n",
      " 56.766666666666666 54.03333333333333 53.93333333333333 56.5\n",
      " 56.666666666666664 50.36666666666667 10.933333333333334\n",
      " 31.533333333333335 34.36666666666667 51.4 53.166666666666664\n",
      " 49.03333333333333 49.5 50.2 50.9 49.0 49.733333333333334 45.3\n",
      " 42.333333333333336 47.766666666666666 44.13333333333333 5.9\n",
      " 44.13333333333333 43.2 43.2 38.766666666666666 38.86666666666667 42.5\n",
      " 43.333333333333336 24.4 41.86666666666667 42.733333333333334\n",
      " 37.53333333333333 39.63333333333333 10.166666666666666 37.63333333333333\n",
      " 38.96666666666667 3.533333333333333 36.9 35.53333333333333\n",
      " 24.733333333333334 38.43333333333333 34.8 33.2 36.2 33.93333333333333\n",
      " 33.6 33.06666666666667 31.533333333333335 2.8666666666666667\n",
      " 30.566666666666666 31.133333333333333 30.233333333333334\n",
      " 24.866666666666667 27.9 28.3 30.366666666666667 30.9 30.333333333333332\n",
      " 27.2 17.333333333333332 23.3 26.7 24.7 3.8666666666666667 14.6\n",
      " 59.666666666666664 1.4333333333333333 44.56666666666667 66.56666666666666\n",
      " 65.86666666666666 60.733333333333334 10.8 50.8 45.766666666666666\n",
      " 45.86666666666667 44.9 38.13333333333333 34.53333333333333\n",
      " 42.03333333333333 30.866666666666667 27.433333333333334\n",
      " 27.933333333333334 60.86666666666667 21.366666666666667 65.36666666666666\n",
      " 64.9 66.3 20.033333333333335 57.2 54.4 18.266666666666666 49.2 46.7\n",
      " 51.36666666666667 46.93333333333333 45.96666666666667 43.833333333333336\n",
      " 44.86666666666667 45.266666666666666 42.96666666666667 43.93333333333333\n",
      " 37.43333333333333 38.8 38.766666666666666 38.3 35.43333333333333 35.8\n",
      " 26.866666666666667 59.266666666666666 5.133333333333334 45.53333333333333\n",
      " 41.266666666666666 41.733333333333334 41.8 38.86666666666667\n",
      " 37.56666666666667 36.86666666666667 35.233333333333334 32.7\n",
      " 26.266666666666666 66.3 65.73333333333333 64.76666666666667\n",
      " 66.33333333333333 30.2 65.66666666666667 60.43333333333333\n",
      " 65.73333333333333 65.13333333333334 27.3 26.633333333333333\n",
      " 63.53333333333333 59.733333333333334 59.6 23.566666666666666 59.9\n",
      " 60.53333333333333 61.0 23.566666666666666 16.233333333333334\n",
      " 56.333333333333336 14.133333333333333 15.966666666666667\n",
      " 16.166666666666668 49.86666666666667 1.6333333333333333 48.0\n",
      " 44.36666666666667 45.06666666666667 40.733333333333334 42.733333333333334\n",
      " 39.93333333333333 39.7 39.6 41.4 39.266666666666666 39.36666666666667\n",
      " 39.4 38.13333333333333 38.333333333333336 34.93333333333333\n",
      " 34.06666666666667 35.93333333333333 36.2 3.033333333333333 31.5\n",
      " 34.766666666666666 30.2 29.633333333333333 22.2 29.2 27.966666666666665\n",
      " 26.733333333333334 67.03333333333333 65.06666666666666 59.6\n",
      " 57.766666666666666 64.13333333333334 57.3 59.06666666666667\n",
      " 61.03333333333333 57.1 61.46666666666667 59.56666666666667\n",
      " 60.233333333333334 56.833333333333336 57.7 57.233333333333334\n",
      " 55.96666666666667 51.1 51.96666666666667 40.86666666666667\n",
      " 44.166666666666664 49.5 47.7 48.7 48.333333333333336 48.56666666666667\n",
      " 45.53333333333333 45.766666666666666 44.233333333333334\n",
      " 45.333333333333336 44.56666666666667 45.333333333333336 40.6\n",
      " 42.13333333333333 42.233333333333334 42.733333333333334 42.03333333333333\n",
      " 40.86666666666667 37.233333333333334 36.9 38.7 36.7 36.06666666666667\n",
      " 36.96666666666667 36.766666666666666 4.566666666666666 31.066666666666666\n",
      " 34.56666666666667 32.233333333333334 29.933333333333334\n",
      " 30.633333333333333 32.233333333333334 29.966666666666665\n",
      " 29.433333333333334 29.666666666666668 26.9 62.6 25.466666666666665\n",
      " 19.833333333333332 18.1 58.833333333333336 39.233333333333334\n",
      " 32.233333333333334 65.83333333333333 14.833333333333334 13.6\n",
      " 53.46666666666667 44.53333333333333 36.333333333333336 18.4 27.6\n",
      " 57.43333333333333 33.53333333333333 59.43333333333333 59.43333333333333\n",
      " 54.06666666666667 47.63333333333333 45.9 43.0 39.43333333333333\n",
      " 29.933333333333334 11.066666666666666 58.266666666666666 60.9\n",
      " 60.63333333333333 54.56666666666667 54.166666666666664 53.56666666666667\n",
      " 28.266666666666666 54.46666666666667 45.96666666666667 44.666666666666664\n",
      " 39.6 40.3 39.93333333333333 37.43333333333333 33.06666666666667\n",
      " 29.433333333333334 30.133333333333333 30.133333333333333 60.3\n",
      " 59.63333333333333 4.366666666666666 53.93333333333333 39.333333333333336\n",
      " 1.2666666666666666 22.8 20.8 57.43333333333333 53.4 54.266666666666666\n",
      " 45.233333333333334 48.13333333333333 42.46666666666667 38.4 59.3 51.9\n",
      " 41.2 54.63333333333333 27.3 10.333333333333334 16.466666666666665\n",
      " 13.633333333333333 55.56666666666667 35.9 32.63333333333333\n",
      " 28.133333333333333 46.6 51.43333333333333 26.7 55.1 60.7\n",
      " 57.266666666666666 56.766666666666666 57.06666666666667\n",
      " 27.166666666666668 49.86666666666667 44.833333333333336 35.86666666666667\n",
      " 42.53333333333333 41.63333333333333 38.93333333333333 36.733333333333334\n",
      " 36.2 27.1 22.233333333333334 12.133333333333333 45.766666666666666 45.0\n",
      " 43.86666666666667 42.4 42.8 26.9 29.933333333333334 14.1 54.3\n",
      " 53.43333333333333 44.93333333333333 3.533333333333333 31.1 33.0\n",
      " 54.36666666666667 54.86666666666667 51.4 51.666666666666664 36.1 48.8\n",
      " 45.06666666666667 45.5 43.233333333333334 40.1 43.1 42.266666666666666\n",
      " 42.333333333333336 27.533333333333335 38.5 39.03333333333333\n",
      " 36.53333333333333 36.7 35.96666666666667 33.43333333333333\n",
      " 31.466666666666665 33.3 32.96666666666667 33.233333333333334\n",
      " 32.93333333333333 33.2 30.4 30.133333333333333 30.166666666666668\n",
      " 30.366666666666667 27.333333333333332 26.866666666666667\n",
      " 25.966666666666665 59.6 58.13333333333333 32.666666666666664\n",
      " 40.56666666666667 32.733333333333334 30.166666666666668\n",
      " 29.433333333333334 26.9 34.833333333333336 47.1 53.0 8.6 35.0\n",
      " 5.233333333333333 33.86666666666667 28.266666666666666 50.666666666666664\n",
      " 38.833333333333336 23.733333333333334 21.433333333333334\n",
      " 48.06666666666667 45.2 14.0 44.333333333333336 33.233333333333334\n",
      " 46.03333333333333 44.56666666666667 41.06666666666667 7.1\n",
      " 9.066666666666666 30.3 27.366666666666667 26.466666666666665\n",
      " 49.06666666666667 48.0 4.733333333333333 29.433333333333334\n",
      " 36.03333333333333 43.53333333333333 33.03333333333333 36.7\n",
      " 29.133333333333333 44.4 9.333333333333334 36.666666666666664\n",
      " 5.733333333333333 50.86666666666667 50.833333333333336 46.766666666666666\n",
      " 48.3 9.566666666666666 42.0 38.7 32.7 27.533333333333335 49.2\n",
      " 47.93333333333333 39.53333333333333 46.3 42.13333333333333 35.8\n",
      " 33.43333333333333 44.733333333333334 44.13333333333333 41.8\n",
      " 42.53333333333333 42.06666666666667 40.86666666666667 42.266666666666666\n",
      " 41.8 40.53333333333333 29.666666666666668 46.56666666666667\n",
      " 48.766666666666666 49.766666666666666 46.5 43.63333333333333 42.9\n",
      " 42.53333333333333 42.233333333333334 41.166666666666664 40.93333333333333\n",
      " 38.96666666666667 38.666666666666664 31.866666666666667\n",
      " 28.566666666666666 39.93333333333333 35.96666666666667 30.066666666666666\n",
      " 24.3 30.133333333333333 41.166666666666664 3.066666666666667\n",
      " 36.166666666666664 35.06666666666667 3.3 33.4 6.633333333333334\n",
      " 36.36666666666667 35.266666666666666 45.03333333333333 41.4\n",
      " 39.46666666666667 39.3 38.833333333333336 39.06666666666667\n",
      " 37.766666666666666 23.833333333333332 42.333333333333336\n",
      " 42.03333333333333 42.333333333333336 42.3 42.06666666666667\n",
      " 38.766666666666666 38.9 32.666666666666664 30.6 28.466666666666665\n",
      " 29.966666666666665 36.06666666666667 20.133333333333333 35.7\n",
      " 33.43333333333333 44.86666666666667 41.63333333333333 35.46666666666667\n",
      " 39.03333333333333 36.43333333333333 35.333333333333336 29.433333333333334\n",
      " 30.3 27.133333333333333 26.866666666666667 26.2 21.933333333333334\n",
      " 29.566666666666666 28.8 28.966666666666665 26.733333333333334\n",
      " 28.266666666666666 27.5 35.43333333333333 27.166666666666668 42.5\n",
      " 34.166666666666664 39.266666666666666 21.2 35.733333333333334\n",
      " 20.866666666666667 36.43333333333333 31.866666666666667 12.8\n",
      " 32.266666666666666 32.4 35.9 18.266666666666666 36.46666666666667\n",
      " 37.666666666666664 39.766666666666666 29.2 26.666666666666668\n",
      " 41.666666666666664 39.8 4.166666666666667 30.633333333333333\n",
      " 26.966666666666665 28.233333333333334 45.0 41.733333333333334\n",
      " 37.766666666666666 36.266666666666666 10.6 29.333333333333332\n",
      " 36.06666666666667 4.433333333333334 6.866666666666666 2.7333333333333334\n",
      " 32.733333333333334 32.3 8.666666666666666 29.5 2.5 27.4 40.0\n",
      " 41.833333333333336 3.033333333333333 31.666666666666668 25.8\n",
      " 41.233333333333334 39.03333333333333 40.166666666666664 36.06666666666667\n",
      " 29.966666666666665 32.766666666666666 31.166666666666668\n",
      " 26.833333333333332 39.333333333333336 32.56666666666667\n",
      " 39.266666666666666 36.43333333333333 39.3 34.6 29.933333333333334\n",
      " 25.233333333333334 32.53333333333333 33.0 33.1 30.8 27.333333333333332\n",
      " 27.1 35.4 35.63333333333333 29.6 30.033333333333335 26.733333333333334\n",
      " 35.9 20.333333333333332 9.733333333333333 11.233333333333333\n",
      " 6.333333333333333 11.333333333333334 9.233333333333333 15.0\n",
      " 3.1666666666666665 12.3 9.866666666666667 0.43333333333333335\n",
      " 6.033333333333333 2.2 13.066666666666666 10.766666666666667 12.6 0.3\n",
      " 11.233333333333333 6.1 5.233333333333333 7.9 1.4666666666666666\n",
      " 6.766666666666667 16.933333333333334 58.43333333333333 10.9\n",
      " 10.466666666666667 27.666666666666668 20.333333333333332 36.4\n",
      " 7.933333333333334 52.13333333333333 5.0 39.0 19.166666666666668 1.5 33.5\n",
      " 31.9 14.6 31.133333333333333 22.266666666666666 27.3 44.3\n",
      " 58.666666666666664 32.53333333333333 39.36666666666667 55.53333333333333\n",
      " 34.43333333333333 5.066666666666666 39.2 13.0 13.466666666666667\n",
      " 11.566666666666666 31.533333333333335 20.933333333333334\n",
      " 21.333333333333332 31.266666666666666 19.866666666666667 28.3 25.7\n",
      " 9.033333333333333 15.833333333333334 4.633333333333334 27.466666666666665\n",
      " 19.333333333333332 18.433333333333334 5.566666666666666\n",
      " 10.666666666666666 8.9 25.933333333333334 8.633333333333333\n",
      " 2.466666666666667 4.7 55.666666666666664 44.266666666666666\n",
      " 23.066666666666666 54.93333333333333 8.333333333333334 2.8333333333333335\n",
      " 32.4 15.433333333333334 38.233333333333334 30.566666666666666\n",
      " 0.5333333333333333 39.2 0.5333333333333333 24.3 9.733333333333333\n",
      " 18.066666666666666 11.033333333333333 1.5333333333333334 18.8\n",
      " 30.466666666666665 59.233333333333334 56.46666666666667 3.7\n",
      " 12.433333333333334 13.533333333333333 15.5 1.3 20.333333333333332\n",
      " 8.933333333333334 5.1 6.9 25.633333333333333 17.566666666666666\n",
      " 1.3666666666666667 22.566666666666666 11.733333333333333 49.0\n",
      " 18.966666666666665 34.166666666666664 39.666666666666664\n",
      " 5.833333333333333 2.3 53.0 1.5 7.933333333333334 16.466666666666665\n",
      " 10.266666666666667 23.933333333333334 1.0333333333333334 20.0\n",
      " 27.866666666666667 16.1 29.733333333333334 1.5333333333333334\n",
      " 1.3666666666666667 18.2 6.7 38.93333333333333 26.5 50.0 11.8\n",
      " 15.633333333333333 26.533333333333335 17.433333333333334\n",
      " 30.366666666666667 28.733333333333334 6.2 31.133333333333333 41.5 64.8\n",
      " 13.366666666666667 9.0 59.63333333333333 43.9 45.4 4.466666666666667 20.1\n",
      " 16.166666666666668 61.666666666666664 30.7 8.0 17.633333333333333 29.0\n",
      " 3.933333333333333 44.166666666666664 7.033333333333333 6.5 8.8\n",
      " 53.86666666666667 49.0 12.4 6.366666666666666 3.7666666666666666 3.9 44.4\n",
      " 37.0 36.666666666666664 12.733333333333333 44.833333333333336\n",
      " 45.53333333333333 17.333333333333332 4.633333333333334 57.666666666666664\n",
      " 22.7 23.233333333333334 22.733333333333334 31.666666666666668\n",
      " 20.966666666666665 13.366666666666667 37.9 0.7666666666666667 31.2\n",
      " 0.6333333333333333 28.033333333333335 20.533333333333335 12.0 24.8\n",
      " 38.333333333333336 42.0 5.133333333333334 29.7 21.566666666666666\n",
      " 23.466666666666665 21.4 28.3 7.9 2.6333333333333333 29.366666666666667\n",
      " 22.2 10.933333333333334 0.7 15.3 2.1333333333333333 12.966666666666667\n",
      " 3.2 25.433333333333334 4.1 15.5 4.333333333333333 17.933333333333334\n",
      " 26.933333333333334 19.233333333333334 19.133333333333333\n",
      " 19.166666666666668 14.166666666666666 3.466666666666667\n",
      " 15.633333333333333 27.1 27.966666666666665 6.7 0.43333333333333335 3.0\n",
      " 17.766666666666666 2.566666666666667 32.63333333333333 11.466666666666667\n",
      " 10.3 4.1 3.3666666666666667 42.6 17.3 10.833333333333334\n",
      " 9.433333333333334 15.133333333333333 17.566666666666666\n",
      " 10.766666666666667 14.1 27.3 18.866666666666667 2.4 20.666666666666668\n",
      " 31.5 15.833333333333334 23.566666666666666 34.1 32.766666666666666\n",
      " 26.066666666666666 14.033333333333333 21.8 14.966666666666667 8.8 2.7 7.7\n",
      " 22.966666666666665 14.966666666666667 25.366666666666667\n",
      " 2.566666666666667 36.46666666666667 17.066666666666666 32.53333333333333\n",
      " 12.966666666666667 21.266666666666666 24.7 11.633333333333333 2.2 3.2 5.2\n",
      " 18.833333333333332 20.7 2.533333333333333 4.5 10.6 9.7 9.733333333333333\n",
      " 1.8 0.26666666666666666 6.933333333333334]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if outcomes_type == 'mortality':\n",
    "    fig, axlist = plt.subplots(1,1)\n",
    "    sns.distplot(new_dset['y_data'][new_dset['event_obs']==1],label='observed', ax = axlist, kde=False)\n",
    "    sns.distplot(new_dset['y_data'][new_dset['event_obs']==0],label='censored', ax = axlist, kde=False)\n",
    "    axlist.legend(fontsize=18)\n",
    "    axlist.set_xlim([0,70])\n",
    "elif outcomes_type == 'trt_resp': \n",
    "    fig, axlist = plt.subplots(1,1)\n",
    "    sns.distplot(new_dset['y_data'], ax = axlist, kde=False)\n",
    "    print(len(np.where(new_dset['y_data']==1.)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if outcomes_type == 'mortality':\n",
    "    fig, axlist = plt.subplots(1,1)\n",
    "    sns.distplot(new_dset_2mos['y_data'][new_dset_2mos['event_obs']==1],label='observed', ax = axlist, kde=False)\n",
    "    sns.distplot(new_dset_2mos['y_data'][new_dset_2mos['event_obs']==0],label='censored', ax = axlist, kde=False)\n",
    "    axlist.legend(fontsize=18)\n",
    "    axlist.set_xlim([0,70])\n",
    "elif outcomes_type == 'trt_resp': \n",
    "    fig, axlist = plt.subplots(1,1)\n",
    "    sns.distplot(new_dset_2mos['y_data'], ax = axlist, kde=False)\n",
    "    print(len(np.where(new_dset['y_data']==1.)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean baseline values (to be in a range -7 to 7ish where 0 corresponds to reference [max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference values for lab measurements\n",
    "# min/max/scale (calculated by attempting to ensure that max labs lie b/w 5-8)\n",
    "healthy_mins_max = {\n",
    "    'cbc_abs_neut':(2., 7.5,1/3.), # abs neutrophil count (3.67, 1.), (2.83, 4.51)\n",
    "    'chem_albumin':(34, 50,1/8.), # chemical albumin (43.62, 2.77), (41.30, 45.94)\n",
    "    'chem_bun':(2.5, 7.1,1/5.), #BUN # reference range, (4.8, 1.15)\n",
    "    'chem_calcium':(2.2, 2.7,2.), #Calcium, (2.45, 0.125)\n",
    "    'chem_creatinine':(66, 112,1/36.), # creatinine, (83., 24.85), (62.22, 103.77)\n",
    "    'chem_glucose':(3.9, 6.9,1/5.), # glucose, (4.91, 0.40), (4.58, 5.24)\n",
    "    'cbc_hemoglobin':(13., 17.,1), # hemoglobin (12.90, 15.64), (8.86, 1.02)\n",
    "    'chem_ldh':(2.33, 4.67,1/3.), #LDH, (3.5, 0.585)\n",
    "    'serum_m_protein':(0.1, 1.1, 1), # M protein (<3 g/dL is MGUS, any presence of protein is pathological); am just using the data mean/std for this, (0.85, 1.89)\n",
    "    'urine_24hr_m_protein':(0.0, 0.1, 1), # Urine M protein \n",
    "    'cbc_platelet':(150, 400,1/60.), # platelet count (206.42, 334.57), (270.5, 76.63)\n",
    "    'chem_totprot':(6, 8,1/6.), # total protein, (7, 0.5)\n",
    "    'urine_24hr_total_protein':(0, 0.23, 1), # \n",
    "    'cbc_wbc':(3, 10,1/4.), # WBC  (5.71, 8.44), (7.07, 1.63)\n",
    "    'serum_iga':(0.85, 4.99, 1.), # IgA, (2.92, 1.035)\n",
    "    'serum_igg':(6.10, 16.16,1/10.), # IgG, (11.13, 2.515)\n",
    "    'serum_igm':(0.35, 2.42,1), #IgM, (1.385, 0.518)\n",
    "    'serum_lambda':(0.57, 2.63, 1/2.), #serum lambda, (1.6, 0.515)\n",
    "    'serum_kappa':(.33, 1.94,1/8.), #serum kappa , (1.135, 0.403)\n",
    "    'serum_beta2_microglobulin':(0.7, 1.80, 1/3.), #serum_beta2_microglobulin,\n",
    "    'serum_c_reactive_protein':(0.0, 1., 1.) #serum_c_reactive_protein,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A] Before cleaning\n",
      "idx, featurename, min, mean, max\n",
      "0 iss 1.0 1.853668071059385 3.0\n",
      "1 age 27.0 63.926073926073926 93.0\n",
      "2 gender 1.0 1.3956043956043955 2.0\n",
      "3 ecog 0.0 0.8791469194312789 4.0\n",
      "4 serum_beta2_microglobulin 0.20800000000000002 5.097520940528193 22.400000000000002\n",
      "5 PC1 -30.66659494 -0.976063433574628 140.0614706\n",
      "6 PC2 -34.81806261 1.4875103276082826 115.7871011\n",
      "7 PC3 -57.38038138 -1.6638067204016924 51.23220332\n",
      "8 PC4 -36.28005205 -2.1831262046966544 44.84930211\n",
      "9 PC5 -37.58013775 0.041447565897195254 50.21645239\n",
      "10 heavy_chain False 0.8551448551448552 True\n",
      "11 igg_type False 0.6313686313686314 True\n",
      "12 iga_type False 0.1798201798201798 True\n",
      "13 igm_type False 0.057942057942057944 True\n",
      "14 kappa_type False 0.6423576423576424 True\n",
      "15 lambda_type False 0.34065934065934067 True\n",
      "------\n",
      "------\n",
      "C] After cleaning\n",
      "0 iss 1.0 1.853668 3.0 False\n",
      "1 age -3.480064 -9.9083046e-08 2.7400453 False\n",
      "2 gender -1.0 -0.20879121 1.0 False\n",
      "3 ecog -0.06479224 -4.0967027e-08 0.23000352 False\n",
      "4 serum_beta2_microglobulin -0.3603527 -2.0388242e-07 1.275174 False\n",
      "5 PC1 -2.188161 -3.048709e-08 10.394317 False\n",
      "6 PC2 -2.6756823 -3.048709e-08 8.4237585 False\n",
      "7 PC3 -4.1062527 1.7148988e-08 3.89838 False\n",
      "8 PC4 -2.5129075 -1.2957014e-07 3.46624 False\n",
      "9 PC5 -2.772671 -2.2865319e-08 3.6978447 False\n",
      "10 heavy_chain 0.0 0.85514486 1.0 False\n",
      "11 igg_type 0.0 0.63136864 1.0 False\n",
      "12 iga_type 0.0 0.17982018 1.0 False\n",
      "13 igm_type 0.0 0.05794206 1.0 False\n",
      "14 kappa_type 0.0 0.64235765 1.0 False\n",
      "15 lambda_type 0.0 0.34065935 1.0 False\n"
     ]
    }
   ],
   "source": [
    "clean_baseline(new_dset, healthy_mins_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A] Before cleaning\n",
      "idx, featurename, min, mean, max\n",
      "0 iss 1.0 1.853668071059385 3.0\n",
      "1 age 27.0 63.926073926073926 93.0\n",
      "2 gender 1.0 1.3956043956043955 2.0\n",
      "3 ecog 0.0 0.8791469194312789 4.0\n",
      "4 serum_beta2_microglobulin 0.20800000000000002 5.097520940528193 22.400000000000002\n",
      "5 PC1 -30.66659494 -0.976063433574628 140.0614706\n",
      "6 PC2 -34.81806261 1.4875103276082826 115.7871011\n",
      "7 PC3 -57.38038138 -1.6638067204016924 51.23220332\n",
      "8 PC4 -36.28005205 -2.1831262046966544 44.84930211\n",
      "9 PC5 -37.58013775 0.041447565897195254 50.21645239\n",
      "10 heavy_chain False 0.8551448551448552 True\n",
      "11 igg_type False 0.6313686313686314 True\n",
      "12 iga_type False 0.1798201798201798 True\n",
      "13 igm_type False 0.057942057942057944 True\n",
      "14 kappa_type False 0.6423576423576424 True\n",
      "15 lambda_type False 0.34065934065934067 True\n",
      "------\n",
      "------\n",
      "C] After cleaning\n",
      "0 iss 1.0 1.853668 3.0 False\n",
      "1 age -3.480064 -9.9083046e-08 2.7400453 False\n",
      "2 gender -1.0 -0.20879121 1.0 False\n",
      "3 ecog -0.06479224 -4.0967027e-08 0.23000352 False\n",
      "4 serum_beta2_microglobulin -0.3603527 -2.0388242e-07 1.275174 False\n",
      "5 PC1 -2.188161 -3.048709e-08 10.394317 False\n",
      "6 PC2 -2.6756823 -3.048709e-08 8.4237585 False\n",
      "7 PC3 -4.1062527 1.7148988e-08 3.89838 False\n",
      "8 PC4 -2.5129075 -1.2957014e-07 3.46624 False\n",
      "9 PC5 -2.772671 -2.2865319e-08 3.6978447 False\n",
      "10 heavy_chain 0.0 0.85514486 1.0 False\n",
      "11 igg_type 0.0 0.63136864 1.0 False\n",
      "12 iga_type 0.0 0.17982018 1.0 False\n",
      "13 igm_type 0.0 0.05794206 1.0 False\n",
      "14 kappa_type 0.0 0.64235765 1.0 False\n",
      "15 lambda_type 0.0 0.34065935 1.0 False\n"
     ]
    }
   ],
   "source": [
    "clean_baseline(new_dset_2mos, healthy_mins_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean time-series lab values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A] Before cleaning\n",
      "idx, featurename, min, mean, max\n",
      "0 cbc_abs_neut 0.0 0.5549595137159506 19.5\n",
      "1 chem_albumin 0.0 6.260265638491302 140.0\n",
      "2 chem_bun 0.0 1.042465920157021 33.56\n",
      "3 chem_calcium 0.0 0.3769780743551606 4.25\n",
      "4 chem_creatinine 0.0 16.41395541818832 429.31999999999994\n",
      "5 chem_glucose 0.0 1.009521451814893 32.775\n",
      "6 cbc_hemoglobin 0.0 1.2582387884851496 11.655999999999999\n",
      "7 serum_kappa -9.9 0.6336436295167748 14.66\n",
      "8 serum_m_protein 0.0 0.10591833363156253 5.6499999999999995\n",
      "9 cbc_platelet 0.0 31.6945748750533 732.0\n",
      "10 chem_totprot 0.0 1.127625304525121 17.1\n",
      "11 cbc_wbc 0.0 0.919796573772325 29.5\n",
      "12 serum_iga 0.0 0.2044903184435668 9.0\n",
      "13 serum_igg 0.0 1.6750832519719485 49.050000000000004\n",
      "14 serum_igm -0.16 0.05189592709003776 6.4\n",
      "15 serum_lambda 0.0 0.37923260921512597 11.35\n",
      "------\n",
      "B] Subtracting healthy max  7.5  from cbc_abs_neut  and scaling:  0.3333333333333333\n",
      "B] Subtracting healthy max  50  from chem_albumin  and scaling:  0.125\n",
      "B] Subtracting healthy max  7.1  from chem_bun  and scaling:  0.2\n",
      "B] Subtracting healthy max  2.7  from chem_calcium  and scaling:  2.0\n",
      "B] Subtracting healthy max  112  from chem_creatinine  and scaling:  0.027777777777777776\n",
      "B] Subtracting healthy max  6.9  from chem_glucose  and scaling:  0.2\n",
      "B] Subtracting healthy max  17.0  from cbc_hemoglobin  and scaling:  1\n",
      "B] Subtracting healthy max  1.94  from serum_kappa  and scaling:  0.125\n",
      "B] Subtracting healthy max  1.1  from serum_m_protein  and scaling:  1\n",
      "B] Subtracting healthy max  400  from cbc_platelet  and scaling:  0.016666666666666666\n",
      "B] Subtracting healthy max  8  from chem_totprot  and scaling:  0.16666666666666666\n",
      "B] Subtracting healthy max  10  from cbc_wbc  and scaling:  0.25\n",
      "B] Subtracting healthy max  4.99  from serum_iga  and scaling:  1.0\n",
      "B] Subtracting healthy max  16.16  from serum_igg  and scaling:  0.1\n",
      "B] Subtracting healthy max  2.42  from serum_igm  and scaling:  1\n",
      "B] Subtracting healthy max  2.63  from serum_lambda  and scaling:  0.5\n",
      "------\n",
      "C] After cleaning\n",
      "0 cbc_abs_neut -2.5 -2.3150136 4.0\n",
      "1 chem_albumin -6.25 -5.467467 11.25\n",
      "2 chem_bun -1.42 -1.2115067 5.2920003\n",
      "3 chem_calcium -5.4 -4.6460443 3.1\n",
      "4 chem_creatinine -3.1111112 -2.6551678 8.814445\n",
      "5 chem_glucose -1.38 -1.1780957 5.1750007\n",
      "6 cbc_hemoglobin -17.0 -15.741762 -5.344\n",
      "7 serum_kappa -1.48 -0.16329457 1.5899999\n",
      "8 serum_m_protein -1.1 -0.9940818 4.55\n",
      "9 cbc_platelet -6.666667 -6.1384234 5.533334\n",
      "10 chem_totprot -1.3333334 -1.1453958 1.5166668\n",
      "11 cbc_wbc -2.5 -2.2700508 4.875\n",
      "12 serum_iga -4.99 -4.785509 4.01\n",
      "13 serum_igg -1.616 -1.4484913 3.289\n",
      "14 serum_igm -2.5800002 -2.368104 3.98\n",
      "15 serum_lambda -1.315 -1.125384 4.36\n",
      "A] Before cleaning\n",
      "idx, featurename, min, mean, max\n",
      "0 cbc_abs_neut 0.0 1.0922268105578667 19.5\n",
      "1 chem_albumin 0.0 12.334922945919727 140.0\n",
      "2 chem_bun 0.0 2.0538522290162486 33.56\n",
      "3 chem_calcium 0.0 0.74275401750819 4.25\n",
      "4 chem_creatinine 0.0 32.34019745884508 429.31999999999994\n",
      "5 chem_glucose 0.0 1.9894362981140896 32.775\n",
      "6 cbc_hemoglobin 0.0 2.4782017316035447 11.655999999999999\n",
      "7 serum_kappa -9.9 1.2494011148746782 14.66\n",
      "8 serum_m_protein 0.0 0.20843643113561622 5.6499999999999995\n",
      "9 cbc_platelet 0.0 62.336232969917106 732.0\n",
      "10 chem_totprot 0.0 2.2217320064407304 17.1\n",
      "11 cbc_wbc 0.0 1.809455406497818 29.5\n",
      "12 serum_iga 0.0 0.4027628243965939 9.0\n",
      "13 serum_igg 0.0 3.3033692406011794 49.050000000000004\n",
      "14 serum_igm -0.16 0.10247919714014576 6.4\n",
      "15 serum_lambda 0.0 0.7471499579331732 11.35\n",
      "------\n",
      "B] Subtracting healthy max  7.5  from cbc_abs_neut  and scaling:  0.3333333333333333\n",
      "B] Subtracting healthy max  50  from chem_albumin  and scaling:  0.125\n",
      "B] Subtracting healthy max  7.1  from chem_bun  and scaling:  0.2\n",
      "B] Subtracting healthy max  2.7  from chem_calcium  and scaling:  2.0\n",
      "B] Subtracting healthy max  112  from chem_creatinine  and scaling:  0.027777777777777776\n",
      "B] Subtracting healthy max  6.9  from chem_glucose  and scaling:  0.2\n",
      "B] Subtracting healthy max  17.0  from cbc_hemoglobin  and scaling:  1\n",
      "B] Subtracting healthy max  1.94  from serum_kappa  and scaling:  0.125\n",
      "B] Subtracting healthy max  1.1  from serum_m_protein  and scaling:  1\n",
      "B] Subtracting healthy max  400  from cbc_platelet  and scaling:  0.016666666666666666\n",
      "B] Subtracting healthy max  8  from chem_totprot  and scaling:  0.16666666666666666\n",
      "B] Subtracting healthy max  10  from cbc_wbc  and scaling:  0.25\n",
      "B] Subtracting healthy max  4.99  from serum_iga  and scaling:  1.0\n",
      "B] Subtracting healthy max  16.16  from serum_igg  and scaling:  0.1\n",
      "B] Subtracting healthy max  2.42  from serum_igm  and scaling:  1\n",
      "B] Subtracting healthy max  2.63  from serum_lambda  and scaling:  0.5\n",
      "------\n",
      "C] After cleaning\n",
      "0 cbc_abs_neut -2.5 -2.1359243 4.0\n",
      "1 chem_albumin -6.25 -4.7081347 11.25\n",
      "2 chem_bun -1.42 -1.0092295 5.2920003\n",
      "3 chem_calcium -5.4 -3.9144924 3.1\n",
      "4 chem_creatinine -3.1111112 -2.2127724 8.814445\n",
      "5 chem_glucose -1.38 -0.9821127 5.1750007\n",
      "6 cbc_hemoglobin -17.0 -14.521798 -5.344\n",
      "7 serum_kappa -1.48 -0.08632489 1.5899999\n",
      "8 serum_m_protein -1.1 -0.8915637 4.55\n",
      "9 cbc_platelet -6.666667 -5.6277294 5.533334\n",
      "10 chem_totprot -1.3333334 -0.9630446 1.5166668\n",
      "11 cbc_wbc -2.5 -2.047636 4.875\n",
      "12 serum_iga -4.99 -4.587236 4.01\n",
      "13 serum_igg -1.616 -1.2856631 3.289\n",
      "14 serum_igm -2.5800002 -2.3175206 3.98\n",
      "15 serum_lambda -1.315 -0.94142514 4.36\n"
     ]
    }
   ],
   "source": [
    "clean_labs(new_dset, healthy_mins_max)\n",
    "clean_labs(new_dset_2mos, healthy_mins_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get censorship balanced train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  1001\n",
      "Total:  700\n",
      "Fold:  0 489 211\n",
      "Event obs:  125 55\n",
      "Total:  700\n",
      "Fold:  1 489 211\n",
      "Event obs:  125 55\n",
      "Total:  700\n",
      "Fold:  2 489 211\n",
      "Event obs:  125 55\n",
      "Total:  700\n",
      "Fold:  3 489 211\n",
      "Event obs:  125 55\n",
      "Total:  700\n",
      "Fold:  4 489 211\n",
      "Event obs:  125 55\n"
     ]
    }
   ],
   "source": [
    "# train_valid_folds, testidx = get_splits(new_dset['y_data'], nfolds=5)\n",
    "train_valid_folds, testidx = get_splits(new_dset['event_obs'], nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('folds.pkl'):\n",
    "    train_valid_folds, testidx = get_splits(new_dset['event_obs'], nfolds = 5)\n",
    "    with open('folds.pkl','wb') as f:\n",
    "        pickle.dump((train_valid_folds, testidx),f)\n",
    "else:\n",
    "    print ('Reading...')\n",
    "    with open('folds.pkl','rb') as f:\n",
    "        train_valid_folds, testidx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split dataset for 5 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    print ('Saving fold ', fold)\n",
    "    final_dataset = {}\n",
    "    final_dataset[fold] = {}\n",
    "    for tvt in ['train','valid','test']:\n",
    "        if  tvt =='test':\n",
    "            idx = testidx\n",
    "        elif tvt =='train':\n",
    "            idx = train_valid_folds[fold][0]\n",
    "        elif tvt == 'valid':\n",
    "            idx = train_valid_folds[fold][1]\n",
    "        else:\n",
    "            raise NotImplemented()\n",
    "        final_dataset[fold][tvt] = {}\n",
    "        final_dataset[fold][tvt]['pids']   = new_dset['patient_ids'][idx]\n",
    "        # labs\n",
    "        final_dataset[fold][tvt]['x']      = new_dset['labs_data_clean'][idx]\n",
    "        final_dataset[fold][tvt]['m']    = new_dset['labs_m'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names_x']    = new_dset['labs_names']\n",
    "        # outcomes\n",
    "        final_dataset[fold][tvt]['ys_seq'] = new_dset['y_data'][idx].reshape(-1,1)\n",
    "        final_dataset[fold][tvt]['ce']     = (1.-new_dset['event_obs'][idx]).reshape(-1,1)\n",
    "        # baseline\n",
    "        final_dataset[fold][tvt]['b']      = new_dset['baseline_data_clean'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names']    = new_dset['baseline_names']\n",
    "        # treatments\n",
    "        final_dataset[fold][tvt]['a']      = new_dset['treatment_data'][idx]\n",
    "        final_dataset[fold][tvt]['m_a']    = new_dset['treatment_m'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names_a']    = new_dset['treatment_names']\n",
    "    \n",
    "    # Forward fill missing data in longitudinal lab tensors\n",
    "    for tvt in ['train','valid','test']:\n",
    "        x_new  = np.copy(final_dataset[fold][tvt]['x'])\n",
    "        x_new[final_dataset[fold][tvt]['m']==0] = np.nan\n",
    "        x_new_filled  = []\n",
    "        for k in range(x_new.shape[-1]):\n",
    "            x_new_filled.append(pd.DataFrame(x_new[...,k]).fillna(method='ffill', axis=1).values[...,None])\n",
    "        x_new_filled  = np.concatenate(x_new_filled, axis=-1)\n",
    "        assert not np.any(np.isnan(x_new_filled)),'should not be any nans'\n",
    "        final_dataset[fold][tvt]['x'] = x_new_filled\n",
    "    \n",
    "    # Restrict (in train/valid set) to patients with atleast two longitudinal observations\n",
    "    T_lb = 2\n",
    "    for tvt in ['train']:\n",
    "        M     = final_dataset[fold][tvt]['m']\n",
    "        M_t   = (M.sum(-1)>1.)*1.\n",
    "        all_t = M_t.sum(-1)\n",
    "        keep_idx = np.argwhere(all_t>T_lb).ravel()\n",
    "        if tvt == 'train':\n",
    "            C = final_dataset[fold][tvt]['ce']\n",
    "            print ('Before: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "        for kk in ['a','x','m','ys_seq','ce','b','pids','m_a']:\n",
    "            final_dataset[fold][tvt][kk] = np.copy(final_dataset[fold][tvt][kk][keep_idx])\n",
    "        if tvt == 'train':\n",
    "            C = final_dataset[fold][tvt]['ce']\n",
    "            print ('After: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "\n",
    "    with open('cleaned_mm'+str(fold)+'.pkl','wb') as f:\n",
    "        pickle.dump(final_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1074, 33, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dset_2mos['treatment_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortality\n",
      "Saving fold  0\n",
      "train...\n",
      "Before: N censored/total  364.0 489 0.7443762781186094\n",
      "After: N censored/total  335.0 434 0.771889400921659\n",
      "(434, 33, 16)\n",
      "valid...\n",
      "Before: N censored/total  156.0 211 0.7393364928909952\n",
      "test...\n",
      "Before: N censored/total  223.0 301 0.7408637873754153\n",
      "\n",
      "Saving fold  1\n",
      "train...\n",
      "Before: N censored/total  364.0 489 0.7443762781186094\n",
      "After: N censored/total  338.0 436 0.7752293577981652\n",
      "(436, 33, 16)\n",
      "valid...\n",
      "Before: N censored/total  156.0 211 0.7393364928909952\n",
      "test...\n",
      "Before: N censored/total  223.0 301 0.7408637873754153\n",
      "\n",
      "Saving fold  2\n",
      "train...\n",
      "Before: N censored/total  364.0 489 0.7443762781186094\n",
      "After: N censored/total  340.0 437 0.7780320366132724\n",
      "(437, 33, 16)\n",
      "valid...\n",
      "Before: N censored/total  156.0 211 0.7393364928909952\n",
      "test...\n",
      "Before: N censored/total  223.0 301 0.7408637873754153\n",
      "\n",
      "Saving fold  3\n",
      "train...\n",
      "Before: N censored/total  364.0 489 0.7443762781186094\n",
      "After: N censored/total  335.0 434 0.771889400921659\n",
      "(434, 33, 16)\n",
      "valid...\n",
      "Before: N censored/total  156.0 211 0.7393364928909952\n",
      "test...\n",
      "Before: N censored/total  223.0 301 0.7408637873754153\n",
      "\n",
      "Saving fold  4\n",
      "train...\n",
      "Before: N censored/total  364.0 489 0.7443762781186094\n",
      "After: N censored/total  343.0 443 0.7742663656884876\n",
      "(443, 33, 16)\n",
      "valid...\n",
      "Before: N censored/total  156.0 211 0.7393364928909952\n",
      "test...\n",
      "Before: N censored/total  223.0 301 0.7408637873754153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(outcomes_type)\n",
    "for fold in range(5):\n",
    "    print ('Saving fold ', fold)\n",
    "    final_dataset = {}\n",
    "    final_dataset[fold] = {}\n",
    "    for tvt in ['train','valid','test']:\n",
    "        if  tvt =='test':\n",
    "            idx = testidx\n",
    "        elif tvt =='train':\n",
    "            idx = train_valid_folds[fold][0]\n",
    "        elif tvt == 'valid':\n",
    "            idx = train_valid_folds[fold][1]\n",
    "        else:\n",
    "            raise NotImplemented()\n",
    "        final_dataset[fold][tvt] = {}\n",
    "        final_dataset[fold][tvt]['pids']               = new_dset_2mos['patient_ids'][idx]\n",
    "        # labs\n",
    "        final_dataset[fold][tvt]['x']                  = new_dset_2mos['labs_data_clean'][idx]\n",
    "        final_dataset[fold][tvt]['m']                  = new_dset_2mos['labs_m'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names_x']    = new_dset_2mos['labs_names']\n",
    "        # outcomes\n",
    "        final_dataset[fold][tvt]['ys_seq'] = new_dset_2mos['y_data'][idx].reshape(-1,1)\n",
    "        final_dataset[fold][tvt]['ce']     = (1.-new_dset_2mos['event_obs'][idx]).reshape(-1,1)\n",
    "        if outcomes_type == 'trt_resp': \n",
    "            final_dataset[fold][tvt]['feature_names_y']    = new_dset_2mos['tr_names']\n",
    "        # baseline\n",
    "        final_dataset[fold][tvt]['b']      = new_dset_2mos['baseline_data_clean'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names']    = new_dset_2mos['baseline_names']\n",
    "        # treatments\n",
    "        final_dataset[fold][tvt]['a']      = new_dset_2mos['treatment_data'][idx]\n",
    "        final_dataset[fold][tvt]['m_a']    = new_dset_2mos['treatment_m'][idx]\n",
    "        final_dataset[fold][tvt]['feature_names_a']    = new_dset_2mos['treatment_names']\n",
    "    \n",
    "    # Forward fill missing data in longitudinal lab tensors\n",
    "    for tvt in ['train','valid','test']:\n",
    "        x_new  = np.copy(final_dataset[fold][tvt]['x'])\n",
    "        x_new[final_dataset[fold][tvt]['m']==0] = np.nan\n",
    "        x_new_filled  = []\n",
    "        for k in range(x_new.shape[-1]):\n",
    "            x_new_filled.append(pd.DataFrame(x_new[...,k]).fillna(method='ffill', axis=1).values[...,None])\n",
    "        x_new_filled  = np.concatenate(x_new_filled, axis=-1)\n",
    "        assert not np.any(np.isnan(x_new_filled)),'should not be any nans'\n",
    "        final_dataset[fold][tvt]['x'] = x_new_filled\n",
    "    \n",
    "    # Restrict (in train/valid set) to patients with atleast two longitudinal observations\n",
    "    T_lb = 2\n",
    "    print(f'train...')\n",
    "    for tvt in ['train']:\n",
    "        M     = final_dataset[fold][tvt]['m']\n",
    "        M_t   = (M.sum(-1)>1.)*1.\n",
    "        all_t = M_t.sum(-1)\n",
    "        keep_idx = np.argwhere(all_t>T_lb).ravel()\n",
    "        if tvt == 'train':\n",
    "            if outcomes_type == 'mortality':\n",
    "                C = final_dataset[fold][tvt]['ce']\n",
    "                print ('Before: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "            elif outcomes_type == 'trt_resp': \n",
    "                Y = final_dataset[fold][tvt]['ys_seq']\n",
    "                C = final_dataset[fold][tvt]['ce']\n",
    "                print ('Before: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "                for i in range(np.max(Y)+1): \n",
    "                    print (f'Before: Y class {i}, N: {len(np.where(Y == i)[0])}')\n",
    "        for kk in ['a','x','m','ys_seq','ce','b','pids','m_a']:\n",
    "            final_dataset[fold][tvt][kk] = np.copy(final_dataset[fold][tvt][kk][keep_idx])\n",
    "        if tvt == 'train':\n",
    "            if outcomes_type == 'mortality':\n",
    "                C = final_dataset[fold][tvt]['ce']\n",
    "                print ('After: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "            elif outcomes_type == 'trt_resp': \n",
    "                Y = final_dataset[fold][tvt]['ys_seq']\n",
    "                C = final_dataset[fold][tvt]['ce']\n",
    "                print ('After: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "                for i in range(np.max(Y)+1): \n",
    "                    print (f'After: Y class {i}, N: {len(np.where(Y == i)[0])}')\n",
    "    print (final_dataset[fold]['train']['x'].shape)\n",
    "    for tvt in ['valid', 'test']: \n",
    "        print(f'{tvt}...')\n",
    "        if outcomes_type == 'mortality':\n",
    "            C = final_dataset[fold][tvt]['ce']\n",
    "            print ('Before: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "        elif outcomes_type == 'trt_resp': \n",
    "            Y = final_dataset[fold][tvt]['ys_seq']\n",
    "            C = final_dataset[fold][tvt]['ce']\n",
    "            print ('Before: N censored/total ',C.sum(), C.shape[0], C.sum()/C.shape[0])\n",
    "            for i in range(np.max(Y)+1): \n",
    "                print (f'Before: Y class {i}, N: {len(np.where(Y == i)[0])}')\n",
    "    print()\n",
    "    with open('cleaned_mm'+str(fold)+'_2mos.pkl','wb') as f:\n",
    "        pickle.dump(final_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
