{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from process_mmrf import get_sequential_tensor, merge_on_pids, parse_baseline, parse_outcomes, parse_treatments, parse_labs, parse_trt_outcomes\n",
    "from fancyimpute import KNN as KNN_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia_version = 'ia13'\n",
    "if ia_version == 'ia13':\n",
    "    FDIR  = '/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles'\n",
    "elif ia_version == 'ia15': \n",
    "    FDIR  = '/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia15/CoMMpass_IA15_FlatFiles'\n",
    "else:\n",
    "    raise ValueError('Bad ia version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_PER_PATIENT_VISIT.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (5,9,11,12,13,14,15,16,17,18,23,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,55,57,58,60,61,62,63,64,66,68,70,71,73,75,76,77,78,79,80,83,84,85,87,90,91,92,94,97,98,99,100,101,103,106,107,108,110,113,114,115,117,120,121,122,126,127,130,132,133,138,139,141,142,143,144,145,147,148,149,150,151,152,153,155,156,157,158,159,160,161,162,163,165,166,167,168,169,170,177,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,218,224,225,226,227,232,233,242,245,248,251,274,279,291,292,378,380,421,424,426,428,431,433,435,438,440,442,445,447,449,450,451,453,455,457,458,459,460,461,462,463,464,465,466,467,468,469,470,472,475,478,480,482,485,487,489,492,494,496,499,501,503,506,508,510,513,515,517,520,522,524,527,529,531,534,536,538,541,543,545,548,550,567,571,572,573,574,575,583,585,587,588,589,590,591,592,593,594,595,597,600,601,602,603,604,606,609,610,611,613,614,616,617,619,624,625,626,627,628,630,631) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_MEDHX.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_SURVIVAL.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_EMERGENCY_DEPT.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_PER_PATIENT.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_TRTRESP.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_AE.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_FAMHX.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_TREATMENT_REGIMEN.csv\n",
      "/afs/csail.mit.edu/group/clinicalml/datasets/multiple_myeloma/ia13/CoMMpass_IA13_FlatFiles/MMRF_CoMMpass_IA13_STAND_ALONE_ADMISSIONS.csv\n",
      "dict_keys(['PER_PATIENT_VISIT', 'STAND_ALONE_MEDHX', 'STAND_ALONE_SURVIVAL', 'STAND_ALONE_EMERGENCY_DEPT', 'PER_PATIENT', 'STAND_ALONE_TRTRESP', 'STAND_ALONE_AE', 'STAND_ALONE_FAMHX', 'STAND_ALONE_TREATMENT_REGIMEN', 'STAND_ALONE_ADMISSIONS'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (27,77,78,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_files = {}\n",
    "for fullname in glob.glob(FDIR+'/*.csv'):\n",
    "    print (fullname)\n",
    "    fname = os.path.basename(fullname).split('.')[0]\n",
    "    if 'MMRF_CoMMpass_IA13_' in fname:\n",
    "        kname = fname.split('MMRF_CoMMpass_IA13_')[1]\n",
    "    else:\n",
    "        kname = fname\n",
    "    data_files[kname] = pd.read_csv(fullname, delimiter=',', encoding='latin-1')\n",
    "print (data_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['treatment'] = {}\n",
    "dataset['labs']      = {}\n",
    "dataset['baseline']  = {}\n",
    "dataset['outcomes']  = {}\n",
    "dataset['trt_outcomes'] = {}\n",
    "\n",
    "dataset_2mos = {}\n",
    "dataset_2mos['treatment'] = {}\n",
    "dataset_2mos['labs']      = {}\n",
    "dataset_2mos['baseline']  = {}\n",
    "dataset_2mos['outcomes']  = {}\n",
    "dataset_2mos['trt_outcomes'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/pandas/core/frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_ppv        = data_files['PER_PATIENT_VISIT']\n",
    "baseline_labs = ['D_LAB_cbc_abs_neut', 'D_LAB_chem_albumin', 'D_LAB_chem_bun', 'D_LAB_chem_calcium', 'D_LAB_chem_creatinine',\n",
    "        'D_LAB_chem_glucose', 'D_LAB_cbc_hemoglobin', 'D_LAB_serum_kappa', 'D_LAB_serum_m_protein', 'D_LAB_cbc_platelet',\n",
    "        'D_LAB_chem_totprot', 'D_LAB_cbc_wbc', 'D_LAB_serum_iga', 'D_LAB_serum_igg', 'D_LAB_serum_igm', 'D_LAB_serum_beta2_microglobulin',\n",
    "        'D_LAB_serum_lambda']\n",
    "df_bl = df_ppv[['PUBLIC_ID','VISIT','VISITDY']+baseline_labs]\n",
    "df_bl.rename(columns = dict([(k,k.split('D_LAB_')[1]) for k in baseline_labs]), inplace=True)\n",
    "baseline_labs = np.array([k.split('D_LAB_')[1] for k in baseline_labs])\n",
    "\n",
    "df_bl = df_bl[df_bl.VISIT==0].reset_index(drop=True)\n",
    "df_bl = df_bl.groupby('PUBLIC_ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914\n",
      "188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# add heavy chain/light chain feature, and specific myeloma type vector \n",
    "serum_labs = ['serum_m_protein', 'serum_iga', 'serum_igg', 'serum_igm', 'serum_lambda', 'serum_kappa']\n",
    "df_test = df_bl[serum_labs]\n",
    "df_test['serum_igg'] = df_test['serum_igg'] * 100.\n",
    "df_test['serum_iga'] = df_test['serum_iga'] * 100.\n",
    "df_test['serum_igm'] = df_test['serum_igm'] * 100. \n",
    "df_test['kl_ratio']  = df_test['serum_kappa'] / df_test['serum_lambda'] \n",
    "\n",
    "# 1 if heavy chain, 0 if light chain \n",
    "new_df = df_test['serum_m_protein']>0.5\n",
    "new_df[df_test['serum_m_protein'].isnull()] = np.NaN\n",
    "df_test['heavy_chain'] = new_df\n",
    "\n",
    "print((df_test['heavy_chain'] == 1.).sum())\n",
    "print((df_test['heavy_chain'] == 0.).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_labs: clipped values to 5x median (before/after)\n",
      "                                     0            1\n",
      "cbc_abs_neut                   16.512    16.512000\n",
      "chem_albumin                   54.000    54.000000\n",
      "chem_bun                       52.122    52.122000\n",
      "chem_calcium                    4.250     4.250000\n",
      "chem_creatinine              1986.348  1354.259987\n",
      "chem_glucose                   16.940    16.940000\n",
      "cbc_hemoglobin                  9.982     9.982000\n",
      "serum_kappa                455000.000   166.500000\n",
      "serum_m_protein                12.270    12.270000\n",
      "cbc_platelet                  668.000   668.000000\n",
      "chem_totprot                   17.100    17.100000\n",
      "cbc_wbc                        34.600    34.600000\n",
      "serum_iga                     276.630    21.450000\n",
      "serum_igg                     147.000   147.000000\n",
      "serum_igm                      84.200    18.000000\n",
      "serum_beta2_microglobulin      37.900    37.900000\n",
      "serum_lambda                46200.000    32.490000\n"
     ]
    }
   ],
   "source": [
    "medians = df_bl[baseline_labs].median(0)\n",
    "maxval  = (15*(1+medians))\n",
    "clipped = df_bl[baseline_labs].clip(upper = maxval, axis=1)\n",
    "print ('parse_labs: clipped values to 5x median (before/after)\\n',pd.concat([df_bl[baseline_labs].max(0), clipped[baseline_labs].max(0)],axis=1))\n",
    "df_bl.loc[:,baseline_labs] = clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_treatments: treatments:  ['Bor' 'Car' 'Cyc' 'Dex' 'Len']\n",
      "parse_treatments: adding line of therapy:  ['Bor' 'Car' 'Cyc' 'Dex' 'Len' 'line']\n",
      "parse_treatments:processing... 0 Bor\n",
      "\ttget_sequential_tensor: feature name/values: Bor [1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor Bor: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "parse_treatments:processing... 1 Car\n",
      "\ttget_sequential_tensor: feature name/values: Car [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor Car: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "parse_treatments:processing... 2 Cyc\n",
      "\ttget_sequential_tensor: feature name/values: Cyc [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor Cyc: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "parse_treatments:processing... 3 Dex\n",
      "\ttget_sequential_tensor: feature name/values: Dex [1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor Dex: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "parse_treatments:processing... 4 Len\n",
      "\ttget_sequential_tensor: feature name/values: Len [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor Len: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "parse_treatments:processing... 5 line\n",
      "\ttget_sequential_tensor: feature name/values: line [1 2 3 4 5 9]\n",
      "\ttget_sequential_tensor: did not hit second line for MMRF_1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf_v1/process_mmrf.py:25: UserWarning: \tget_sequential_tensor line: Found days that exceed set maximum time\n",
      "  warnings.warn('\\tget_sequential_tensor %s: Found days that exceed set maximum time'%(feature_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "merge_on_pids: intersection of patient ids is 1143\n",
      "merge_on_pids: after merging, pat_ids, data, obs: 1143 (1143, 66, 6) (1143, 66, 6)\n",
      "parse_treatments: 1143 (1143, 66, 6) (1143, 66, 6)\n",
      "parse_treatments: treatments:  ['Bor' 'Car' 'Cyc' 'Dex' 'Len']\n",
      "parse_treatments: adding line of therapy:  ['Bor' 'Car' 'Cyc' 'Dex' 'Len' 'line']\n",
      "parse_treatments:processing... 0 Bor\n",
      "\ttget_sequential_tensor: feature name/values: Bor [1 0]\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "parse_treatments:processing... 1 Car\n",
      "\ttget_sequential_tensor: feature name/values: Car [0 1]\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "parse_treatments:processing... 2 Cyc\n",
      "\ttget_sequential_tensor: feature name/values: Cyc [0 1]\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "parse_treatments:processing... 3 Dex\n",
      "\ttget_sequential_tensor: feature name/values: Dex [1 0]\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "parse_treatments:processing... 4 Len\n",
      "\ttget_sequential_tensor: feature name/values: Len [0 1]\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "parse_treatments:processing... 5 line\n",
      "\ttget_sequential_tensor: feature name/values: line [1 2 3 4 5 9]\n",
      "\ttget_sequential_tensor: did not hit second line for MMRF_1007\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "merge_on_pids: intersection of patient ids is 1143\n",
      "merge_on_pids: after merging, pat_ids, data, obs: 1143 (1143, 33, 6) (1143, 33, 6)\n",
      "parse_treatments: 1143 (1143, 33, 6) (1143, 33, 6)\n"
     ]
    }
   ],
   "source": [
    "tpids, tdata, tobs, tnames = parse_treatments(data_files['STAND_ALONE_TRTRESP'])\n",
    "dataset['treatment']['pids'] = tpids; dataset['treatment']['data'] = tdata\n",
    "dataset['treatment']['obs']  = tobs;  dataset['treatment']['names'] = tnames\n",
    "\n",
    "tpids, tdata, tobs, tnames = parse_treatments(data_files['STAND_ALONE_TRTRESP'], granularity = 60, maxT=33)\n",
    "dataset_2mos['treatment']['pids'] = tpids; dataset_2mos['treatment']['data'] = tdata\n",
    "dataset_2mos['treatment']['obs']  = tobs;  dataset_2mos['treatment']['names'] = tnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_labs: clipped values to 5x median (before/after)\n",
      "                           0        1\n",
      "cbc_abs_neut         69.900   19.500\n",
      "chem_albumin        140.000  140.000\n",
      "chem_bun             52.122   33.560\n",
      "chem_calcium          4.250    4.250\n",
      "chem_creatinine    1986.348  429.320\n",
      "chem_glucose         36.245   32.775\n",
      "cbc_hemoglobin       11.656   11.656\n",
      "serum_kappa      455000.000   14.660\n",
      "serum_m_protein      40.300    5.650\n",
      "cbc_platelet        732.000  732.000\n",
      "chem_totprot         17.100   17.100\n",
      "cbc_wbc              81.000   29.500\n",
      "serum_iga           276.630    9.000\n",
      "serum_igg           147.000   49.050\n",
      "serum_igm            84.200    6.400\n",
      "serum_lambda      46200.000   11.350\n",
      "\n",
      "parse_labs:processing... 0 cbc_abs_neut\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 1 chem_albumin\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 2 chem_bun\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 3 chem_calcium\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 4 chem_creatinine\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 5 chem_glucose\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 6 cbc_hemoglobin\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 7 serum_kappa\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 8 serum_m_protein\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 9 cbc_platelet\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 10 chem_totprot\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 11 cbc_wbc\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 12 serum_iga\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 13 serum_igg\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 14 serum_igm\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "\n",
      "parse_labs:processing... 15 serum_lambda\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 66) (1143, 66)\n",
      "merge_on_pids: intersection of patient ids is 1143\n",
      "merge_on_pids: after merging, pat_ids, data, obs: 1143 (1143, 66, 16) (1143, 66, 16)\n",
      "parse_labs: 1143 (1143, 66, 16) (1143, 66, 16)\n",
      "parse_labs (name/min/max) cbc_abs_neut 0.0 19.5\n",
      "parse_labs (name/min/max) chem_albumin 0.0 140.0\n",
      "parse_labs (name/min/max) chem_bun 0.0 33.56\n",
      "parse_labs (name/min/max) chem_calcium 0.0 4.25\n",
      "parse_labs (name/min/max) chem_creatinine 0.0 429.31999999999994\n",
      "parse_labs (name/min/max) chem_glucose 0.0 32.775\n",
      "parse_labs (name/min/max) cbc_hemoglobin 0.0 11.655999999999999\n",
      "parse_labs (name/min/max) serum_kappa 0.0 14.66\n",
      "parse_labs (name/min/max) serum_m_protein 0.0 5.6499999999999995\n",
      "parse_labs (name/min/max) cbc_platelet 0.0 732.0\n",
      "parse_labs (name/min/max) chem_totprot 0.0 17.1\n",
      "parse_labs (name/min/max) cbc_wbc 0.0 29.5\n",
      "parse_labs (name/min/max) serum_iga 0.0 9.0\n",
      "parse_labs (name/min/max) serum_igg 0.0 49.050000000000004\n",
      "parse_labs (name/min/max) serum_igm -0.16 6.4\n",
      "parse_labs (name/min/max) serum_lambda 0.0 11.35\n",
      "parse_labs: clipped values to 5x median (before/after)\n",
      "                           0        1\n",
      "cbc_abs_neut         69.900   19.500\n",
      "chem_albumin        140.000  140.000\n",
      "chem_bun             52.122   33.560\n",
      "chem_calcium          4.250    4.250\n",
      "chem_creatinine    1986.348  429.320\n",
      "chem_glucose         36.245   32.775\n",
      "cbc_hemoglobin       11.656   11.656\n",
      "serum_kappa      455000.000   14.660\n",
      "serum_m_protein      40.300    5.650\n",
      "cbc_platelet        732.000  732.000\n",
      "chem_totprot         17.100   17.100\n",
      "cbc_wbc              81.000   29.500\n",
      "serum_iga           276.630    9.000\n",
      "serum_igg           147.000   49.050\n",
      "serum_igm            84.200    6.400\n",
      "serum_lambda      46200.000   11.350\n",
      "\n",
      "parse_labs:processing... 0 cbc_abs_neut\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 1 chem_albumin\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 2 chem_bun\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 3 chem_calcium\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 4 chem_creatinine\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 5 chem_glucose\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 6 cbc_hemoglobin\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 7 serum_kappa\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 8 serum_m_protein\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 9 cbc_platelet\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 10 chem_totprot\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 11 cbc_wbc\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 12 serum_iga\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 13 serum_igg\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 14 serum_igm\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "\n",
      "parse_labs:processing... 15 serum_lambda\n",
      "\ttget_sequential_tensor: output shapes: (1143,) (1143, 33) (1143, 33)\n",
      "merge_on_pids: intersection of patient ids is 1143\n",
      "merge_on_pids: after merging, pat_ids, data, obs: 1143 (1143, 33, 16) (1143, 33, 16)\n",
      "parse_labs: 1143 (1143, 33, 17) (1143, 33, 17)\n",
      "parse_labs (name/min/max) cbc_abs_neut 0.0 19.5\n",
      "parse_labs (name/min/max) chem_albumin 0.0 140.0\n",
      "parse_labs (name/min/max) chem_bun 0.0 33.56\n",
      "parse_labs (name/min/max) chem_calcium 0.0 4.25\n",
      "parse_labs (name/min/max) chem_creatinine 0.0 429.31999999999994\n",
      "parse_labs (name/min/max) chem_glucose 0.0 32.775\n",
      "parse_labs (name/min/max) cbc_hemoglobin 0.0 11.655999999999999\n",
      "parse_labs (name/min/max) serum_kappa 0.0 14.66\n",
      "parse_labs (name/min/max) serum_m_protein 0.0 5.6499999999999995\n",
      "parse_labs (name/min/max) cbc_platelet 0.0 732.0\n",
      "parse_labs (name/min/max) chem_totprot 0.0 17.1\n",
      "parse_labs (name/min/max) cbc_wbc 0.0 29.5\n",
      "parse_labs (name/min/max) serum_iga 0.0 9.0\n",
      "parse_labs (name/min/max) serum_igg 0.0 49.050000000000004\n",
      "parse_labs (name/min/max) serum_igm -0.16 6.4\n",
      "parse_labs (name/min/max) serum_lambda 0.0 11.35\n",
      "parse_labs (name/min/max) kl_ratio 0.0 500.0\n"
     ]
    }
   ],
   "source": [
    "lpids, ldata, lobs, lnames = parse_labs(data_files['PER_PATIENT_VISIT'])\n",
    "dataset['labs']['pids'] = lpids; dataset['labs']['data']  = ldata\n",
    "dataset['labs']['obs']  = lobs;  dataset['labs']['names'] = lnames\n",
    "\n",
    "lpids, ldata, lobs, lnames = parse_labs(data_files['PER_PATIENT_VISIT'], granularity = 60, maxT=33, add_kl_ratio=True)\n",
    "dataset_2mos['labs']['pids'] = lpids; dataset_2mos['labs']['data']  = ldata\n",
    "dataset_2mos['labs']['obs']  = lobs;  dataset_2mos['labs']['names'] = lnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_baselines: clipped values to 5x median (before/after)\n",
      "                               0     1\n",
      "serum_beta2_microglobulin  37.9  22.4\n",
      "parse_baselines: do mean imputation on missing data in baseline\n",
      "parse_baselines: doing knn(k=5) imputation for missing genomic data\n",
      "Imputing row 1/1143 with 5 missing, elapsed time: 0.347\n",
      "Imputing row 101/1143 with 0 missing, elapsed time: 0.357\n",
      "Imputing row 201/1143 with 0 missing, elapsed time: 0.364\n",
      "Imputing row 301/1143 with 5 missing, elapsed time: 0.367\n",
      "Imputing row 401/1143 with 0 missing, elapsed time: 0.371\n",
      "Imputing row 501/1143 with 0 missing, elapsed time: 0.376\n",
      "Imputing row 601/1143 with 0 missing, elapsed time: 0.380\n",
      "Imputing row 701/1143 with 5 missing, elapsed time: 0.385\n",
      "Imputing row 801/1143 with 0 missing, elapsed time: 0.390\n",
      "Imputing row 901/1143 with 5 missing, elapsed time: 0.393\n",
      "Imputing row 1001/1143 with 5 missing, elapsed time: 0.397\n",
      "Imputing row 1101/1143 with 5 missing, elapsed time: 0.402\n",
      "parse_baselines: result (1143, 17)\n",
      "parse_baselines: clipped values to 5x median (before/after)\n",
      "                               0     1\n",
      "serum_beta2_microglobulin  37.9  22.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/pandas/core/frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_baselines: do mean imputation on missing data in baseline\n",
      "parse_baselines: doing knn(k=5) imputation for missing genomic data\n",
      "Imputing row 1/1143 with 5 missing, elapsed time: 0.237\n",
      "Imputing row 101/1143 with 0 missing, elapsed time: 0.246\n",
      "Imputing row 201/1143 with 0 missing, elapsed time: 0.252\n",
      "Imputing row 301/1143 with 5 missing, elapsed time: 0.255\n",
      "Imputing row 401/1143 with 0 missing, elapsed time: 0.259\n",
      "Imputing row 501/1143 with 0 missing, elapsed time: 0.263\n",
      "Imputing row 601/1143 with 0 missing, elapsed time: 0.266\n",
      "Imputing row 701/1143 with 5 missing, elapsed time: 0.270\n",
      "Imputing row 801/1143 with 0 missing, elapsed time: 0.275\n",
      "Imputing row 901/1143 with 5 missing, elapsed time: 0.278\n",
      "Imputing row 1001/1143 with 5 missing, elapsed time: 0.282\n",
      "Imputing row 1101/1143 with 5 missing, elapsed time: 0.286\n",
      "parse_baselines: result (1143, 17)\n"
     ]
    }
   ],
   "source": [
    "bpids, bdata, bnames = parse_baseline(data_files['PER_PATIENT'], data_files['PER_PATIENT_VISIT'], ia_version = ia_version)\n",
    "dataset['baseline']['pids']  = bpids\n",
    "dataset['baseline']['data']  = bdata\n",
    "dataset['baseline']['obs']   = np.ones_like(bdata)\n",
    "dataset['baseline']['names'] = bnames\n",
    "\n",
    "bpids, bdata, bnames = parse_baseline(data_files['PER_PATIENT'], data_files['PER_PATIENT_VISIT'], ia_version = ia_version)\n",
    "dataset_2mos['baseline']['pids']  = bpids\n",
    "dataset_2mos['baseline']['data']  = bdata\n",
    "dataset_2mos['baseline']['obs']   = np.ones_like(bdata)\n",
    "dataset_2mos['baseline']['names'] = bnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "* We will use time-to-death as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_outcomes:  (1001,) (1001,) (1001,)\n",
      "parse_outcomes:  (1001,) (1001,) (1001,)\n",
      "parse_outcomes:  (295,) (295,)\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "ypid, Y, E = parse_outcomes(data_files['PER_PATIENT'])\n",
    "dataset['outcomes']['pids'] = ypid\n",
    "dataset['outcomes']['data'] = Y\n",
    "dataset['outcomes']['obs']  = E\n",
    "dataset['outcomes']['names']  = np.array(['mortality'])\n",
    "\n",
    "ypid, Y, E = parse_outcomes(data_files['PER_PATIENT'], granularity = 60)\n",
    "dataset_2mos['outcomes']['pids'] = ypid\n",
    "dataset_2mos['outcomes']['data'] = Y\n",
    "dataset_2mos['outcomes']['obs']  = E\n",
    "dataset_2mos['outcomes']['names']  = np.array(['mortality'])\n",
    "\n",
    "ypid_trt, Ytrt, tr_names = parse_trt_outcomes(data_files['STAND_ALONE_TRTRESP'], from_gateway=False)\n",
    "dataset['trt_outcomes']['pids'] = ypid_trt\n",
    "dataset['trt_outcomes']['data'] = Ytrt \n",
    "dataset['trt_outcomes']['obs']  = np.ones_like(Ytrt)\n",
    "dataset['trt_outcomes']['names'] = tr_names\n",
    "\n",
    "dataset_2mos['trt_outcomes']['pids'] = ypid_trt\n",
    "dataset_2mos['trt_outcomes']['data'] = Ytrt \n",
    "dataset_2mos['trt_outcomes']['obs']  = np.ones_like(Ytrt)\n",
    "dataset_2mos['trt_outcomes']['names'] = tr_names\n",
    "print(Ytrt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save raw tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_mmrf_dataset_type.pkl','wb') as f:\n",
    "    pickle.dump(dataset, f)\n",
    "with open('1_mmrf_dataset_2mos_type.pkl','wb') as f:\n",
    "    pickle.dump(dataset_2mos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
