{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Model for MM Data \n",
    "We will be training and evaluating a first order markov model (FOMM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "sys.path.append('../')\n",
    "from baseline_model import FOMM\n",
    "from data import load_mmrf\n",
    "from base import Model, setup_torch_dataset, pt_numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cuda\n",
      "loading from: /afs/csail.mit.edu/u/z/zeshanmh/research/ml_mmrf/ml_mmrf_v1/cleaned_mm_fold_2mos.pkl\n",
      "Digitizing outcomes ymax: 35.81666666666667\n",
      "20 19 20\n",
      "using digitized y\n",
      "using digitized y\n",
      "using digitized y\n"
     ]
    }
   ],
   "source": [
    "fold = 1 # specify which fold of mm data you want\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device  = torch.device('cpu')\n",
    "print ('Running on: ', device)    \n",
    "mmdata  = load_mmrf(fold_span = [fold], digitize_K = 20, digitize_method = 'uniform', suffix='_2mos')\n",
    "dim_base, dim_data, dim_treat = mmdata[fold]['train']['b'].shape[-1], mmdata[fold]['train']['x'].shape[-1], mmdata[fold]['train']['a'].shape[-1]\n",
    "train, train_loader = setup_torch_dataset(mmdata, fold, 'train', device)\n",
    "valid, valid_loader = setup_torch_dataset(mmdata, fold, 'valid', device)\n",
    "test, test_loader   = setup_torch_dataset(mmdata, fold, 'test', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_hidden = 300\n",
    "model = FOMM(dim_hidden, dim_base, dim_data, dim_treat, mtype = 'linear', C =.1, reg_type = 'l1', reg_all = True)\n",
    "model.to(device)\n",
    "_, nelbo, nll, kl, _ = model.fit_unsupervised(train_loader, valid_loader, 15000, 1e-3, eval_freq=1, print_freq=1000, fname = 'test_model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "(nelbo, nll, kl,_), _ = model.forward_unsupervised(*test_loader.dataset.tensors, anneal = 1.)\n",
    "print(nll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
